{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4480a80c-b8a1-4375-beb6-224ab6613789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34 utterances from /workspace/dataset/S5/features/Ses05M_impro06.pt\n",
      "Utterance IDs: ['Ses05M_impro06_F000', 'Ses05M_impro06_M000', 'Ses05M_impro06_F001', 'Ses05M_impro06_M001', 'Ses05M_impro06_F002']\n",
      "\n",
      "=== Example: Ses05M_impro06_F000 ===\n",
      "{'audio_emb shape': torch.Size([1, 1024]),\n",
      " 'end_time': 6.57,\n",
      " 'start_time': 3.67,\n",
      " 'text': \"Ryan, what's wrong?\",\n",
      " 'text_emb shape': torch.Size([1, 1024]),\n",
      " 'vision_emb shape': torch.Size([1, 1024])}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pprint  # 用来格式化输出\n",
    "\n",
    "# 文件路径\n",
    "pt_path = \"/workspace/dataset/S5/features/Ses05M_impro06.pt\"\n",
    "\n",
    "# 读取文件\n",
    "data = torch.load(pt_path, map_location=\"cpu\")\n",
    "\n",
    "print(f\"Loaded {len(data)} utterances from {pt_path}\")\n",
    "\n",
    "# 查看前几个 key（每个 utterance 的 ID）\n",
    "print(\"Utterance IDs:\", list(data.keys())[:5])\n",
    "\n",
    "# 取出一个样本看看\n",
    "utt_id = list(data.keys())[0]\n",
    "entry = data[utt_id]\n",
    "\n",
    "print(f\"\\n=== Example: {utt_id} ===\")\n",
    "pprint.pprint({\n",
    "    \"start_time\": entry.get(\"start_time\"),\n",
    "    \"end_time\": entry.get(\"end_time\"),\n",
    "    \"text\": entry.get(\"text\"),\n",
    "    \"text_emb shape\": entry[\"text_emb\"].shape,\n",
    "    \"audio_emb shape\": entry[\"audio_emb\"].shape,\n",
    "    \"vision_emb shape\": entry[\"vision_emb\"].shape,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d4cb3a-7604-49ba-bd7e-a841b543c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接所有文本 embedding\n",
    "text_embs = torch.cat([v[\"text_emb\"] for v in data.values()], dim=0)\n",
    "audio_embs = torch.cat([v[\"audio_emb\"] for v in data.values()], dim=0)\n",
    "vision_embs = torch.cat([v[\"vision_emb\"] for v in data.values()], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3779ebf-6f39-4165-a693-8e5add77b9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7944, -2.4691, -0.6758,  ..., -3.4899, -1.0594,  1.9511],\n",
       "        [ 2.3022,  3.2462,  0.9003,  ..., -0.4022, -0.2051,  0.9829],\n",
       "        [-0.7184, -5.3655, -0.0762,  ...,  2.2394,  1.6025, -5.4964],\n",
       "        ...,\n",
       "        [ 1.2145, -0.2882, -0.4721,  ...,  2.2102, -1.5978,  0.2008],\n",
       "        [ 1.7834,  1.2176, -0.7155,  ..., -1.5025, -3.6112, -0.1797],\n",
       "        [-0.3329, -4.4933, -2.5126,  ...,  1.9726, -0.3362, -4.8012]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc87ce9-aa52-4e2a-92bb-99e879030012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 1024])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64cfa9c9-529d-4f0f-b947-639613bd64b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "def load_all_embeddings(base_dir=\"/workspace/dataset\", sessions=[\"S1\", \"S2\", \"S3\", \"S4\", \"S5\"]):\n",
    "    all_data = []\n",
    "    skipped_files = []\n",
    "    loaded_files = 0\n",
    "\n",
    "    for s in sessions:\n",
    "        feature_dir = os.path.join(base_dir, s, \"features\")\n",
    "        if not os.path.exists(feature_dir):\n",
    "            print(f\"[WARN] Missing feature dir: {feature_dir}\")\n",
    "            continue\n",
    "\n",
    "        for fname in os.listdir(feature_dir):\n",
    "            #  只加载包含 with_emo 的文件\n",
    "            if not fname.endswith(\"_with_emo.pt\"):\n",
    "                continue\n",
    "\n",
    "            fpath = os.path.join(feature_dir, fname)\n",
    "            try:\n",
    "                data = torch.load(fpath, map_location=\"cpu\")\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Failed to load {fname}: {e}\")\n",
    "                skipped_files.append(fname)\n",
    "                continue\n",
    "\n",
    "            loaded_files += 1\n",
    "\n",
    "            for utt_id, v in data.items():\n",
    "                # 确保有情感字段才保存\n",
    "                if \"C-E1\" not in v or v[\"C-E1\"] is None:\n",
    "                    continue\n",
    "\n",
    "                all_data.append({\n",
    "                    \"session\": s,\n",
    "                    \"video\": fname.replace(\"_with_emo.pt\", \"\"),\n",
    "                    \"utt_id\": utt_id,\n",
    "                    \"text_emb\": v[\"text_emb\"].squeeze(0),\n",
    "                    \"audio_emb\": v[\"audio_emb\"].squeeze(0),\n",
    "                    \"vision_emb\": v[\"vision_emb\"].squeeze(0),\n",
    "                    \"start_time\": v.get(\"start_time\"),\n",
    "                    \"end_time\": v.get(\"end_time\"),\n",
    "                    \"VAD\": v.get(\"VAD\"),\n",
    "                    \"C-E1\": v.get(\"C-E1\"),\n",
    "                    \"C-E2\": v.get(\"C-E2\"),\n",
    "                    \"C-E4\": v.get(\"C-E4\"),\n",
    "                })\n",
    "\n",
    "    #print(f\"Loaded {loaded_files} files with emotion labels.\")\n",
    "    #print(f\"Total utterances collected: {len(all_data)}\")\n",
    "    #if skipped_files:\n",
    "    #    print(f\"[WARN] Skipped {len(skipped_files)} files: {skipped_files[:5]}\")\n",
    "\n",
    "    return all_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "925867e8-948b-454d-8b1f-4f0ba89679a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiModalBiGRU(nn.Module):\n",
    "    def __init__(self, input_dim=1024*3, hidden_dim=512, num_layers=1, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.bigru = nn.GRU(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, input_dim]\n",
    "        out, _ = self.bigru(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74517737-2546-46d5-b4b5-7923426c3116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1/Ses01F_impro02: GRU output shape = torch.Size([1, 38, 1024])\n",
      "S1/Ses01F_impro03: GRU output shape = torch.Size([1, 52, 1024])\n",
      "S1/Ses01F_impro04: GRU output shape = torch.Size([1, 71, 1024])\n",
      "S1/Ses01F_impro05: GRU output shape = torch.Size([1, 67, 1024])\n",
      "S1/Ses01F_impro06: GRU output shape = torch.Size([1, 47, 1024])\n",
      "S1/Ses01F_impro07: GRU output shape = torch.Size([1, 37, 1024])\n",
      "S1/Ses01F_script01_1: GRU output shape = torch.Size([1, 89, 1024])\n",
      "S1/Ses01F_script01_2: GRU output shape = torch.Size([1, 33, 1024])\n",
      "S1/Ses01F_script01_3: GRU output shape = torch.Size([1, 75, 1024])\n",
      "S1/Ses01F_script03_1: GRU output shape = torch.Size([1, 71, 1024])\n",
      "S1/Ses01F_script03_2: GRU output shape = torch.Size([1, 82, 1024])\n",
      "S1/Ses01M_impro05: GRU output shape = torch.Size([1, 70, 1024])\n",
      "S1/Ses01M_impro02: GRU output shape = torch.Size([1, 48, 1024])\n",
      "S1/Ses01M_impro03: GRU output shape = torch.Size([1, 53, 1024])\n",
      "S1/Ses01M_impro04: GRU output shape = torch.Size([1, 52, 1024])\n",
      "S1/Ses01M_impro01: GRU output shape = torch.Size([1, 65, 1024])\n",
      "S1/Ses01M_impro06: GRU output shape = torch.Size([1, 60, 1024])\n",
      "S1/Ses01M_impro07: GRU output shape = torch.Size([1, 69, 1024])\n",
      "S1/Ses01M_script01_1: GRU output shape = torch.Size([1, 87, 1024])\n",
      "S1/Ses01M_script01_2: GRU output shape = torch.Size([1, 33, 1024])\n",
      "S1/Ses01M_script01_3: GRU output shape = torch.Size([1, 75, 1024])\n",
      "S1/Ses01M_script02_2: GRU output shape = torch.Size([1, 103, 1024])\n",
      "S1/Ses01M_script02_1: GRU output shape = torch.Size([1, 72, 1024])\n",
      "S1/Ses01M_script03_1: GRU output shape = torch.Size([1, 85, 1024])\n",
      "S1/Ses01M_script03_2: GRU output shape = torch.Size([1, 86, 1024])\n",
      "S2/Ses02F_impro01: GRU output shape = torch.Size([1, 49, 1024])\n",
      "S2/Ses02F_impro02: GRU output shape = torch.Size([1, 27, 1024])\n",
      "S2/Ses02F_impro03: GRU output shape = torch.Size([1, 58, 1024])\n",
      "S2/Ses02F_impro04: GRU output shape = torch.Size([1, 39, 1024])\n",
      "S2/Ses02F_impro06: GRU output shape = torch.Size([1, 35, 1024])\n",
      "S2/Ses02F_impro07: GRU output shape = torch.Size([1, 74, 1024])\n",
      "S2/Ses02F_impro08: GRU output shape = torch.Size([1, 48, 1024])\n",
      "S2/Ses02F_script01_1: GRU output shape = torch.Size([1, 90, 1024])\n",
      "S2/Ses02F_script01_2: GRU output shape = torch.Size([1, 38, 1024])\n",
      "S2/Ses02F_script01_3: GRU output shape = torch.Size([1, 67, 1024])\n",
      "S2/Ses02F_script02_1: GRU output shape = torch.Size([1, 68, 1024])\n",
      "S2/Ses02F_script02_2: GRU output shape = torch.Size([1, 93, 1024])\n",
      "S2/Ses02F_script03_1: GRU output shape = torch.Size([1, 66, 1024])\n",
      "S2/Ses02F_script03_2: GRU output shape = torch.Size([1, 92, 1024])\n",
      "S2/Ses02M_impro01: GRU output shape = torch.Size([1, 48, 1024])\n",
      "S2/Ses02M_impro02: GRU output shape = torch.Size([1, 34, 1024])\n",
      "S2/Ses02M_impro03: GRU output shape = torch.Size([1, 61, 1024])\n",
      "S2/Ses02M_impro04: GRU output shape = torch.Size([1, 41, 1024])\n",
      "S2/Ses02M_impro05: GRU output shape = torch.Size([1, 60, 1024])\n",
      "S2/Ses02M_impro06: GRU output shape = torch.Size([1, 43, 1024])\n",
      "S2/Ses02M_impro07: GRU output shape = torch.Size([1, 63, 1024])\n",
      "S2/Ses02M_impro08: GRU output shape = torch.Size([1, 63, 1024])\n",
      "S2/Ses02M_script01_1: GRU output shape = torch.Size([1, 88, 1024])\n",
      "S2/Ses02M_script01_2: GRU output shape = torch.Size([1, 37, 1024])\n",
      "S2/Ses02M_script01_3: GRU output shape = torch.Size([1, 67, 1024])\n",
      "S2/Ses02M_script02_1: GRU output shape = torch.Size([1, 68, 1024])\n",
      "S2/Ses02M_script02_2: GRU output shape = torch.Size([1, 94, 1024])\n",
      "S2/Ses02M_script03_1: GRU output shape = torch.Size([1, 64, 1024])\n",
      "S2/Ses02M_script03_2: GRU output shape = torch.Size([1, 91, 1024])\n",
      "S3/Ses03F_impro01: GRU output shape = torch.Size([1, 24, 1024])\n",
      "S3/Ses03F_impro02: GRU output shape = torch.Size([1, 76, 1024])\n",
      "S3/Ses03F_impro03: GRU output shape = torch.Size([1, 47, 1024])\n",
      "S3/Ses03F_impro04: GRU output shape = torch.Size([1, 48, 1024])\n",
      "S3/Ses03F_impro05: GRU output shape = torch.Size([1, 33, 1024])\n",
      "S3/Ses03F_impro06: GRU output shape = torch.Size([1, 53, 1024])\n",
      "S3/Ses03F_impro07: GRU output shape = torch.Size([1, 72, 1024])\n",
      "S3/Ses03F_impro08: GRU output shape = torch.Size([1, 57, 1024])\n",
      "S3/Ses03F_script01_1: GRU output shape = torch.Size([1, 108, 1024])\n",
      "S3/Ses03F_script01_2: GRU output shape = torch.Size([1, 41, 1024])\n",
      "S3/Ses03F_script01_3: GRU output shape = torch.Size([1, 83, 1024])\n",
      "S3/Ses03F_script02_1: GRU output shape = torch.Size([1, 67, 1024])\n",
      "S3/Ses03F_script02_2: GRU output shape = torch.Size([1, 99, 1024])\n",
      "S3/Ses03F_script03_1: GRU output shape = torch.Size([1, 61, 1024])\n",
      "S3/Ses03F_script03_2: GRU output shape = torch.Size([1, 89, 1024])\n",
      "S3/Ses03M_impro01: GRU output shape = torch.Size([1, 56, 1024])\n",
      "S3/Ses03M_impro02: GRU output shape = torch.Size([1, 76, 1024])\n",
      "S3/Ses03M_impro03: GRU output shape = torch.Size([1, 84, 1024])\n",
      "S3/Ses03M_impro04: GRU output shape = torch.Size([1, 75, 1024])\n",
      "S3/Ses03M_impro05a: GRU output shape = torch.Size([1, 60, 1024])\n",
      "S3/Ses03M_impro05b: GRU output shape = torch.Size([1, 66, 1024])\n",
      "S3/Ses03M_impro06: GRU output shape = torch.Size([1, 54, 1024])\n",
      "S3/Ses03M_impro07: GRU output shape = torch.Size([1, 51, 1024])\n",
      "S3/Ses03M_impro08a: GRU output shape = torch.Size([1, 64, 1024])\n",
      "S3/Ses03M_impro08b: GRU output shape = torch.Size([1, 48, 1024])\n",
      "S3/Ses03M_script01_1: GRU output shape = torch.Size([1, 95, 1024])\n",
      "S3/Ses03M_script01_2: GRU output shape = torch.Size([1, 38, 1024])\n",
      "S3/Ses03M_script01_3: GRU output shape = torch.Size([1, 82, 1024])\n",
      "S3/Ses03M_script02_1: GRU output shape = torch.Size([1, 68, 1024])\n",
      "S3/Ses03M_script02_2: GRU output shape = torch.Size([1, 97, 1024])\n",
      "S3/Ses03M_script03_1: GRU output shape = torch.Size([1, 71, 1024])\n",
      "S3/Ses03M_script03_2: GRU output shape = torch.Size([1, 93, 1024])\n",
      "S4/Ses04F_impro01: GRU output shape = torch.Size([1, 49, 1024])\n",
      "S4/Ses04F_impro02: GRU output shape = torch.Size([1, 52, 1024])\n",
      "S4/Ses04F_impro03: GRU output shape = torch.Size([1, 104, 1024])\n",
      "S4/Ses04F_impro04: GRU output shape = torch.Size([1, 69, 1024])\n",
      "S4/Ses04F_impro05: GRU output shape = torch.Size([1, 45, 1024])\n",
      "S4/Ses04F_impro06: GRU output shape = torch.Size([1, 26, 1024])\n",
      "S4/Ses04F_impro07: GRU output shape = torch.Size([1, 167, 1024])\n",
      "S4/Ses04F_impro08: GRU output shape = torch.Size([1, 58, 1024])\n",
      "S4/Ses04F_script01_1: GRU output shape = torch.Size([1, 91, 1024])\n",
      "S4/Ses04F_script01_3: GRU output shape = torch.Size([1, 79, 1024])\n",
      "S4/Ses04F_script01_2: GRU output shape = torch.Size([1, 41, 1024])\n",
      "S4/Ses04F_script02_2: GRU output shape = torch.Size([1, 99, 1024])\n",
      "S4/Ses04F_script03_1: GRU output shape = torch.Size([1, 68, 1024])\n",
      "S4/Ses04F_script03_2: GRU output shape = torch.Size([1, 91, 1024])\n",
      "S4/Ses04M_impro01: GRU output shape = torch.Size([1, 47, 1024])\n",
      "S4/Ses04M_impro02: GRU output shape = torch.Size([1, 68, 1024])\n",
      "S4/Ses04M_impro03: GRU output shape = torch.Size([1, 58, 1024])\n",
      "S4/Ses04M_impro04: GRU output shape = torch.Size([1, 43, 1024])\n",
      "S4/Ses04M_impro05: GRU output shape = torch.Size([1, 89, 1024])\n",
      "S4/Ses04M_impro06: GRU output shape = torch.Size([1, 41, 1024])\n",
      "S4/Ses04F_script02_1: GRU output shape = torch.Size([1, 66, 1024])\n",
      "S4/Ses04M_script01_1: GRU output shape = torch.Size([1, 89, 1024])\n",
      "S4/Ses04M_script01_2: GRU output shape = torch.Size([1, 41, 1024])\n",
      "S4/Ses04M_script01_3: GRU output shape = torch.Size([1, 66, 1024])\n",
      "S4/Ses04M_impro08: GRU output shape = torch.Size([1, 60, 1024])\n",
      "S4/Ses04M_script02_2: GRU output shape = torch.Size([1, 81, 1024])\n",
      "S4/Ses04M_script02_1: GRU output shape = torch.Size([1, 56, 1024])\n",
      "S4/Ses04M_script03_1: GRU output shape = torch.Size([1, 65, 1024])\n",
      "S4/Ses04M_script03_2: GRU output shape = torch.Size([1, 110, 1024])\n",
      "S4/Ses04M_impro07: GRU output shape = torch.Size([1, 84, 1024])\n",
      "S5/Ses05F_impro01: GRU output shape = torch.Size([1, 49, 1024])\n",
      "S5/Ses05F_impro02: GRU output shape = torch.Size([1, 81, 1024])\n",
      "S5/Ses05F_impro03: GRU output shape = torch.Size([1, 130, 1024])\n",
      "S5/Ses05F_impro04: GRU output shape = torch.Size([1, 91, 1024])\n",
      "S5/Ses05F_impro05: GRU output shape = torch.Size([1, 100, 1024])\n",
      "S5/Ses05F_impro06: GRU output shape = torch.Size([1, 56, 1024])\n",
      "S5/Ses05F_impro07: GRU output shape = torch.Size([1, 77, 1024])\n",
      "S5/Ses05F_impro08: GRU output shape = torch.Size([1, 67, 1024])\n",
      "S5/Ses05F_script01_1: GRU output shape = torch.Size([1, 83, 1024])\n",
      "S5/Ses05F_script01_2: GRU output shape = torch.Size([1, 36, 1024])\n",
      "S5/Ses05F_script01_3: GRU output shape = torch.Size([1, 68, 1024])\n",
      "S5/Ses05F_script02_1: GRU output shape = torch.Size([1, 55, 1024])\n",
      "S5/Ses05F_script02_2: GRU output shape = torch.Size([1, 81, 1024])\n",
      "S5/Ses05F_script03_1: GRU output shape = torch.Size([1, 68, 1024])\n",
      "S5/Ses05F_script03_2: GRU output shape = torch.Size([1, 86, 1024])\n",
      "S5/Ses05M_impro01: GRU output shape = torch.Size([1, 47, 1024])\n",
      "S5/Ses05M_impro02: GRU output shape = torch.Size([1, 58, 1024])\n",
      "S5/Ses05M_impro03: GRU output shape = torch.Size([1, 66, 1024])\n",
      "S5/Ses05M_impro04: GRU output shape = torch.Size([1, 81, 1024])\n",
      "S5/Ses05M_impro05: GRU output shape = torch.Size([1, 45, 1024])\n",
      "S5/Ses05M_impro06: GRU output shape = torch.Size([1, 32, 1024])\n",
      "S5/Ses05M_impro07: GRU output shape = torch.Size([1, 95, 1024])\n",
      "S5/Ses05M_impro08: GRU output shape = torch.Size([1, 58, 1024])\n",
      "S5/Ses05M_script01_1: GRU output shape = torch.Size([1, 80, 1024])\n",
      "S5/Ses05M_script01_1b: GRU output shape = torch.Size([1, 81, 1024])\n",
      "S5/Ses05M_script01_2: GRU output shape = torch.Size([1, 35, 1024])\n",
      "S5/Ses05M_script01_3: GRU output shape = torch.Size([1, 71, 1024])\n",
      "S5/Ses05M_script02_1: GRU output shape = torch.Size([1, 55, 1024])\n",
      "S5/Ses05M_script02_2: GRU output shape = torch.Size([1, 80, 1024])\n",
      "S5/Ses05M_script03_1: GRU output shape = torch.Size([1, 67, 1024])\n",
      "S5/Ses05M_script03_2: GRU output shape = torch.Size([1, 91, 1024])\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "all_data = load_all_embeddings()\n",
    "# 假设每个视频是一组对话\n",
    "\n",
    "\n",
    "# 按视频分组\n",
    "videos = {}\n",
    "for item in all_data:\n",
    "    key = (item[\"session\"], item[\"video\"])\n",
    "    videos.setdefault(key, []).append(item)\n",
    "\n",
    "# 初始化 BiGRU\n",
    "model = MultiModalBiGRU().to(\"cuda\")\n",
    "\n",
    "for (session, video), utterances in videos.items():\n",
    "    utterances = sorted(utterances, key=lambda x: x[\"start_time\"] or 0.0)\n",
    "    features = []\n",
    "    for u in utterances:\n",
    "        feat = torch.cat([u[\"text_emb\"], u[\"audio_emb\"], u[\"vision_emb\"]], dim=-1)\n",
    "        features.append(feat)\n",
    "    x = torch.stack(features).unsqueeze(0).to(\"cuda\")  # [1, seq_len, 3072]\n",
    "    with torch.no_grad():\n",
    "        output = model(x)\n",
    "    print(f\"{session}/{video}: GRU output shape = {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de43272-17dc-4b0b-9397-f43a1f5bfabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34 utterances from /workspace/dataset/S5/features/Ses05M_impro06_with_emo.pt\n",
      "Utterance IDs: ['Ses05M_impro06_F000', 'Ses05M_impro06_M000', 'Ses05M_impro06_F001', 'Ses05M_impro06_M001', 'Ses05M_impro06_F002']\n",
      "\n",
      "=== Example: Ses05M_impro06_F000 ===\n",
      "{'C-E1': 'Sadness',\n",
      " 'C-E2': 'Neutral',\n",
      " 'C-E4': 'Other',\n",
      " 'VAD': [2.0, 2.0, 1.5],\n",
      " 'audio_emb shape': torch.Size([1, 1024]),\n",
      " 'end_time': 6.57,\n",
      " 'start_time': 3.67,\n",
      " 'text': \"Ryan, what's wrong?\",\n",
      " 'text_emb shape': torch.Size([1, 1024]),\n",
      " 'vision_emb shape': torch.Size([1, 1024])}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pprint  # 用来格式化输出\n",
    "\n",
    "# 文件路径\n",
    "pt_path = \"/workspace/dataset/S5/features/Ses05M_impro06_with_emo.pt\"\n",
    "\n",
    "# 读取文件\n",
    "data = torch.load(pt_path, map_location=\"cpu\")\n",
    "\n",
    "print(f\"Loaded {len(data)} utterances from {pt_path}\")\n",
    "\n",
    "# 查看前几个 key（每个 utterance 的 ID）\n",
    "print(\"Utterance IDs:\", list(data.keys())[:5])\n",
    "\n",
    "# 取出一个样本看看\n",
    "utt_id = list(data.keys())[0]\n",
    "entry = data[utt_id]\n",
    "\n",
    "print(f\"\\n=== Example: {utt_id} ===\")\n",
    "pprint.pprint({\n",
    "    \"start_time\": entry.get(\"start_time\"),\n",
    "    \"end_time\": entry.get(\"end_time\"),\n",
    "    \"text\": entry.get(\"text\"),\n",
    "    \"text_emb shape\": entry[\"text_emb\"].shape,\n",
    "    \"audio_emb shape\": entry[\"audio_emb\"].shape,\n",
    "    \"vision_emb shape\": entry[\"vision_emb\"].shape,\n",
    "    \"VAD\": entry.get(\"VAD\"),\n",
    "    \"C-E1\": entry.get(\"C-E1\"),\n",
    "    \"C-E2\": entry.get(\"C-E2\"),\n",
    "    \"C-E4\": entry.get(\"C-E4\"),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160fc38e-19d1-4094-b950-f3d9a4b0789c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
