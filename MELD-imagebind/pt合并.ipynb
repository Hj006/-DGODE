{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fe8b483-c59c-4630-a201-74c5d0d2e8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging: 100%|██████████| 1108/1108 [00:00<00:00, 4242.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] 合并完成：/workspace/dataset/MELD/dev/all_embeddings.pt  (总样本数=1108)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "SAVE_PATH = \"/workspace/dataset/MELD/dev/pt\"   # 你的单样本 .pt 存放目录\n",
    "OUT_PATH  = \"/workspace/dataset/MELD/dev/all_embeddings.pt\"  # 合并后的总文件\n",
    "\n",
    "# === 可选：分片保存（避免一次太大）===\n",
    "ENABLE_SHARD = False     # 想分片就改 True\n",
    "SHARD_SIZE   = 1000      # 每个分片包含多少个样本\n",
    "SHARD_PREFIX = \"/workspace/dataset/MELD/dev/all_embeddings_shard\"  # 分片前缀\n",
    "\n",
    "def load_one(sample_path):\n",
    "    obj = torch.load(sample_path, map_location=\"cpu\")\n",
    "    # 基本字段校验（按你之前的保存格式）\n",
    "    required_keys = [\"id\", \"text_emb\", \"audio_emb\", \"video_emb\", \"meta\"]\n",
    "    if not all(k in obj for k in required_keys):\n",
    "        raise ValueError(f\"{sample_path} 缺少必要字段，实际键={list(obj.keys())}\")\n",
    "    # 确保张量在 CPU\n",
    "    for k in [\"text_emb\", \"audio_emb\", \"video_emb\"]:\n",
    "        if isinstance(obj[k], torch.Tensor):\n",
    "            obj[k] = obj[k].cpu().contiguous()\n",
    "    return obj\n",
    "\n",
    "def merge_all():\n",
    "    files = sorted(glob.glob(os.path.join(SAVE_PATH, \"*.pt\")))\n",
    "    assert files, f\"目录为空：{SAVE_PATH}\"\n",
    "\n",
    "    seen = set()\n",
    "    merged = []\n",
    "    shard_idx = 0\n",
    "\n",
    "    for fp in tqdm(files, desc=\"Merging\"):\n",
    "        try:\n",
    "            sample = load_one(fp)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] 跳过 {fp}: {e}\")\n",
    "            continue\n",
    "\n",
    "        sid = sample[\"id\"]\n",
    "        if sid in seen:\n",
    "            print(f\"[DUP] 跳过重复 id: {sid}\")\n",
    "            continue\n",
    "        seen.add(sid)\n",
    "        merged.append(sample)\n",
    "\n",
    "        # 分片保存（可选）\n",
    "        if ENABLE_SHARD and len(merged) >= SHARD_SIZE:\n",
    "            shard_path = f\"{SHARD_PREFIX}_{shard_idx:03d}.pt\"\n",
    "            torch.save(merged, shard_path)\n",
    "            print(f\"[SAVE] 分片 -> {shard_path} (samples={len(merged)})\")\n",
    "            shard_idx += 1\n",
    "            merged.clear()\n",
    "\n",
    "    if ENABLE_SHARD:\n",
    "        # 收尾分片\n",
    "        if merged:\n",
    "            shard_path = f\"{SHARD_PREFIX}_{shard_idx:03d}.pt\"\n",
    "            torch.save(merged, shard_path)\n",
    "            print(f\"[SAVE] 分片(最后) -> {shard_path} (samples={len(merged)})\")\n",
    "        print(\"分片保存完成。\")\n",
    "    else:\n",
    "        # 单文件保存\n",
    "        torch.save(merged, OUT_PATH)\n",
    "        print(f\"[DONE] 合并完成：{OUT_PATH}  (总样本数={len(merged)})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56033339-2a57-4a89-8cf8-5d831331db71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1108 dia0_utt0 torch.Size([1, 1024]) torch.Size([1, 1024]) torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.load(\"/workspace/dataset/MELD/dev/dev_embeddings.pt\", map_location=\"cpu\")\n",
    "print(len(data), data[0][\"id\"], data[0][\"text_emb\"].shape, data[0][\"audio_emb\"].shape, data[0][\"video_emb\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79233f31-5ff9-43ce-bf87-4df1d050adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCAN] files on disk: 1108\n",
      "[OK] loadable files: 1108\n",
      "[FAIL] unreadable files: 0\n",
      "[MISS-KEY] missing key files: 0\n",
      "[DUP-ID] duplicate ids: 0\n",
      "[NAME≠ID] filename-id mismatch: 0\n",
      "\n",
      "[SUMMARY] unique ids found: 1108\n"
     ]
    }
   ],
   "source": [
    "import os, glob, torch\n",
    "from collections import defaultdict\n",
    "\n",
    "SAVE_PATH = \"/workspace/dataset/MELD/dev/pt\"\n",
    "\n",
    "files = sorted(glob.glob(os.path.join(SAVE_PATH, \"*.pt\")))\n",
    "print(\"[SCAN] files on disk:\", len(files))\n",
    "\n",
    "failed_load = []\n",
    "missing_keys = []\n",
    "dups = defaultdict(list)\n",
    "id_to_files = defaultdict(list)\n",
    "name_id_mismatch = []\n",
    "\n",
    "for fp in files:\n",
    "    try:\n",
    "        o = torch.load(fp, map_location=\"cpu\")\n",
    "    except Exception as e:\n",
    "        failed_load.append((fp, repr(e)))\n",
    "        continue\n",
    "\n",
    "    # 必要字段\n",
    "    req = [\"id\", \"text_emb\", \"audio_emb\", \"video_emb\", \"meta\"]\n",
    "    if not all(k in o for k in req):\n",
    "        missing_keys.append((fp, list(o.keys())))\n",
    "        continue\n",
    "\n",
    "    sid = o[\"id\"]\n",
    "    id_to_files[sid].append(fp)\n",
    "\n",
    "    # 文件名 vs 内部 id 是否一致（可帮助定位“覆盖/复用 id”的问题）\n",
    "    base = os.path.splitext(os.path.basename(fp))[0]\n",
    "    if base != sid:\n",
    "        name_id_mismatch.append((fp, sid))\n",
    "\n",
    "# 重复 id\n",
    "dup_ids = {k: v for k, v in id_to_files.items() if len(v) > 1}\n",
    "\n",
    "print(\"[OK] loadable files:\", len(files) - len(failed_load))\n",
    "print(\"[FAIL] unreadable files:\", len(failed_load))\n",
    "print(\"[MISS-KEY] missing key files:\", len(missing_keys))\n",
    "print(\"[DUP-ID] duplicate ids:\", len(dup_ids))\n",
    "print(\"[NAME≠ID] filename-id mismatch:\", len(name_id_mismatch))\n",
    "\n",
    "if failed_load:\n",
    "    print(\"\\nUnreadable examples (first 5):\")\n",
    "    for x in failed_load[:5]:\n",
    "        print(\" \", x)\n",
    "\n",
    "if missing_keys:\n",
    "    print(\"\\nMissing-key examples (first 5):\")\n",
    "    for x in missing_keys[:5]:\n",
    "        print(\" \", x)\n",
    "\n",
    "if dup_ids:\n",
    "    print(\"\\nDuplicate id → files (first 5 ids):\")\n",
    "    for i, (k, v) in enumerate(dup_ids.items()):\n",
    "        if i >= 5: break\n",
    "        print(\" \", k, \"->\", v)\n",
    "\n",
    "if name_id_mismatch:\n",
    "    print(\"\\nName vs id mismatch (first 5):\")\n",
    "    for x in name_id_mismatch[:5]:\n",
    "        print(\" \", x)\n",
    "\n",
    "print(\"\\n[SUMMARY] unique ids found:\", len(id_to_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154dcf8d-47f9-4d02-ad91-9cc53613ab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EXPECTED] samples that should be saved: 1108\n",
      "[ON DISK] .pt files: 1108\n",
      "[MISSING] expected but not found: 0\n",
      "[EXTRA] found but not expected: 0\n"
     ]
    }
   ],
   "source": [
    "import os, glob, torch\n",
    "import pandas as pd\n",
    "\n",
    "VIDEO_DIR = \"/workspace/dataset/MELD/dev/dev_splits\"\n",
    "AUDIO_DIR = \"/workspace/dataset/MELD/dev/wav\"\n",
    "SAVE_PATH = \"/workspace/dataset/MELD/dev/pt\"\n",
    "CSV_PATH  = \"/workspace/dataset/MELD/dev/dev_sent_emo.csv\"   # 你提取时用的 df 来源\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "def make_uid(row):\n",
    "    # 按你当时的写法：注意你原始代码是把 Dialogue_ID 转成 int 的\n",
    "    dia_id = int(row[\"Dialogue_ID\"])\n",
    "    utt_id = int(row[\"Utterance_ID\"])\n",
    "    return f\"dia{dia_id}_utt{utt_id}\"\n",
    "\n",
    "# 只有“视频和音频都存在”的才会被保存（你有个 if not exists(video) or not exists(audio): continue）\n",
    "expected = []\n",
    "for _, row in df.iterrows():\n",
    "    uid = make_uid(row)\n",
    "    vp = os.path.join(VIDEO_DIR, f\"{uid}.mp4\")\n",
    "    ap = os.path.join(AUDIO_DIR, f\"{uid}.wav\")\n",
    "    if os.path.exists(vp) and os.path.exists(ap):\n",
    "        expected.append(uid)\n",
    "\n",
    "expected = set(expected)\n",
    "print(\"[EXPECTED] samples that should be saved:\", len(expected))\n",
    "\n",
    "on_disk = { os.path.splitext(os.path.basename(p))[0] \n",
    "            for p in glob.glob(os.path.join(SAVE_PATH, \"*.pt\")) }\n",
    "\n",
    "missing = sorted(expected - on_disk)\n",
    "extra   = sorted(on_disk - expected)\n",
    "\n",
    "print(\"[ON DISK] .pt files:\", len(on_disk))\n",
    "print(\"[MISSING] expected but not found:\", len(missing))\n",
    "print(\"[EXTRA] found but not expected:\", len(extra))\n",
    "\n",
    "if missing:\n",
    "    print(\"\\nMissing examples (first 20):\")\n",
    "    for x in missing[:20]:\n",
    "        print(\" \", x)\n",
    "\n",
    "if extra:\n",
    "    print(\"\\nExtra examples (first 20):\")\n",
    "    for x in extra[:20]:\n",
    "        print(\" \", x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e9e6a9-b9d8-4415-b74b-2cf6b4e33800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 1108\n",
      "\n",
      "id: dia0_utt0\n",
      "text_emb shape : (1, 1024)\n",
      "audio_emb shape: (1, 1024)\n",
      "video_emb shape: (1, 1024)\n",
      "\n",
      "==== meta ====\n",
      "{'Emotion': 'sadness',\n",
      " 'EndTime': '00:21:00,049',\n",
      " 'Episode': 7,\n",
      " 'Season': 4,\n",
      " 'Sentiment': 'negative',\n",
      " 'Speaker': 'Phoebe',\n",
      " 'StartTime': '00:20:57,256'}\n",
      "\n",
      "==== text_emb 前10维 ====\n",
      "tensor([-0.4725,  4.9154,  2.1138, -0.2989, -1.2533,  2.5271,  1.7447,  1.4300,\n",
      "         1.0829, -0.7339])\n",
      "\n",
      "==== audio_emb 前10维 ====\n",
      "tensor([-0.5300,  0.1690, -0.1369,  0.0985, -0.2493,  0.8640,  0.7113, -0.1096,\n",
      "        -0.6751, -0.9109])\n",
      "\n",
      "==== video_emb 前10维 ====\n",
      "tensor([-0.0135,  0.0637, -0.0195, -0.0052,  0.0076,  0.0189,  0.0313, -0.0248,\n",
      "        -0.0190, -0.0358])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pprint import pprint   # pprint 打印字典结构\n",
    "\n",
    "path = \"/workspace/dataset/MELD/dev/dev_embeddings.pt\"\n",
    "data = torch.load(path, map_location=\"cpu\")\n",
    "\n",
    "print(f\"样本总数: {len(data)}\\n\")\n",
    "\n",
    "first = data[0]\n",
    "print(\"id:\", first[\"id\"])\n",
    "print(\"text_emb shape :\", tuple(first[\"text_emb\"].shape))\n",
    "print(\"audio_emb shape:\", tuple(first[\"audio_emb\"].shape))\n",
    "print(\"video_emb shape:\", tuple(first[\"video_emb\"].shape))\n",
    "\n",
    "print(\"\\n==== meta ====\")\n",
    "pprint(first[\"meta\"])  # 结构化打印 meta 字段\n",
    "\n",
    "# 如果你还想看具体的 embedding 数值（前几个即可）\n",
    "print(\"\\n==== text_emb 前10维 ====\")\n",
    "print(first[\"text_emb\"].flatten()[:10])\n",
    "\n",
    "print(\"\\n==== audio_emb 前10维 ====\")\n",
    "print(first[\"audio_emb\"].flatten()[:10])\n",
    "\n",
    "print(\"\\n==== video_emb 前10维 ====\")\n",
    "print(first[\"video_emb\"].flatten()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec03f5-5503-4d9f-b8f4-0087722ab07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
