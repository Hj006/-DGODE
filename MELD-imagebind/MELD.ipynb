{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb63fab6-83b8-43c9-9854-a98432e6428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pandas\n",
      "Successfully installed pandas-2.3.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae589863-04c9-410e-83a6-744d65eb9324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"         # 让 CUDA 报错更早暴露，而不是静默崩\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"           # 设备侧断言（能多报一些越界错误）\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# 先禁用 cudnn，看看是不是 cudnn 的锅（只用在定位阶段；跑通后再打开）\n",
    "torch.backends.cudnn.enabled = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7386ece9-152a-477f-a11a-529a12660cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from imagebind import data\n",
    "from imagebind.models import imagebind_model\n",
    "from imagebind.models.imagebind_model import ModalityType\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51f4556c-a9c4-4586-bde8-d237cadc72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 路径 \n",
    "'''\n",
    "CSV_PATH = \"/workspace/dataset/MELD/dev/dev_sent_emo.csv\"\n",
    "VIDEO_DIR = \"/workspace/dataset/MELD/dev/dev_splits\"\n",
    "AUDIO_DIR = \"/workspace/dataset/MELD/dev/wav\"\n",
    "SAVE_PATH = \"/workspace/dataset/MELD/dev/pt\"\n",
    "'''\n",
    "CSV_PATH = \"/workspace/dataset/MELD/test/test_sent_emo.csv\"\n",
    "VIDEO_DIR = \"/workspace/dataset/MELD/test/test_splits\"\n",
    "AUDIO_DIR = \"/workspace/dataset/MELD/test/wav\"\n",
    "SAVE_PATH = \"/workspace/dataset/MELD/test/pt\"\n",
    "\n",
    "# 模型加载 \n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "model.eval().to(device)\n",
    "\n",
    "# 读 CSV\n",
    "df = pd.read_csv(CSV_PATH, sep=',')  # 若不是\\t，可改成 sep=','\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dbe830b-b8b7-404f-b594-648c6cbbfdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oh my God, hes lost it. Hes totally lost it.</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>00:20:57,256</td>\n",
       "      <td>00:21:00,049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What?</td>\n",
       "      <td>Monica</td>\n",
       "      <td>surprise</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>00:21:01,927</td>\n",
       "      <td>00:21:03,261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Or! Or, we could go to the bank, close our acc...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:24,660</td>\n",
       "      <td>00:12:30,915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Youre a genius!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:32,334</td>\n",
       "      <td>00:12:33,960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Aww, man, now we wont be bank buddies!</td>\n",
       "      <td>Joey</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:34,211</td>\n",
       "      <td>00:12:37,505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr No.                                          Utterance   Speaker  \\\n",
       "0       1     Oh my God, hes lost it. Hes totally lost it.    Phoebe   \n",
       "1       2                                              What?    Monica   \n",
       "2       3  Or! Or, we could go to the bank, close our acc...      Ross   \n",
       "3       4                                   Youre a genius!  Chandler   \n",
       "4       5            Aww, man, now we wont be bank buddies!      Joey   \n",
       "\n",
       "    Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "0   sadness  negative            0             0       4        7   \n",
       "1  surprise  negative            0             1       4        7   \n",
       "2   neutral   neutral            1             0       4        4   \n",
       "3       joy  positive            1             1       4        4   \n",
       "4   sadness  negative            1             2       4        4   \n",
       "\n",
       "      StartTime       EndTime  \n",
       "0  00:20:57,256  00:21:00,049  \n",
       "1  00:21:01,927  00:21:03,261  \n",
       "2  00:12:24,660  00:12:30,915  \n",
       "3  00:12:32,334  00:12:33,960  \n",
       "4  00:12:34,211  00:12:37,505  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de5a35b1-4699-42e2-a532-ebe024edd470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, time, gc, torch\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# 建议：定位时先把 cudnn benchmark 关掉，保持确定性\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def print_gpu_snapshot(tag=\"\"):\n",
    "    \"\"\"打印 cudnn 开关、是否有 CUDA、当前/峰值显存(MB)\"\"\"\n",
    "    alloc = torch.cuda.memory_allocated() / 1024 / 1024\n",
    "    reserved = torch.cuda.memory_reserved() / 1024 / 1024\n",
    "    peak = torch.cuda.max_memory_allocated() / 1024 / 1024\n",
    "    print(f\"[{tag}] cudnn={torch.backends.cudnn.enabled} | \"\n",
    "          f\"CUDA={torch.cuda.is_available()} | \"\n",
    "          f\"alloc={alloc:.1f}MB reserved={reserved:.1f}MB peak={peak:.1f}MB\")\n",
    "\n",
    "def assert_on_cuda(t, name=\"tensor\"):\n",
    "    if torch.is_tensor(t):\n",
    "        print(f\"  {name}: device={t.device} shape={tuple(t.shape)}\")\n",
    "    else:\n",
    "        print(f\"  {name}: (not a tensor)\")\n",
    "\n",
    "@contextmanager\n",
    "def cudnn_off_only_here():\n",
    "    old = torch.backends.cudnn.enabled\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        torch.backends.cudnn.enabled = old\n",
    "\n",
    "def force_cuda_burn():\n",
    "    \"\"\"强制做一次小的 CUDA 计算，验证确实在用 GPU\"\"\"\n",
    "    a = torch.randn(4096, 4096, device=\"cuda\")\n",
    "    b = torch.randn(4096, 4096, device=\"cuda\")\n",
    "    c = (a @ b).sum()\n",
    "    c.item()  # 同步\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce7f8e3-98c2-475b-a564-061e88d25aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data module path: /ImageBind/imagebind/data.py\n",
      "audio func path: /ImageBind/imagebind/data.py\n",
      "waveform2melspec_fixed in module?: False\n"
     ]
    }
   ],
   "source": [
    "from imagebind import data\n",
    "import inspect, importlib\n",
    "print(\"data module path:\", data.__file__)\n",
    "print(\"audio func path:\", inspect.getsourcefile(data.load_and_transform_audio_data))\n",
    "print(\"waveform2melspec_fixed in module?:\", hasattr(data, \"waveform2melspec_fixed\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b072b-f2d6-46d3-af1e-31f6dc008c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2610 [01:16<2:05:09,  2.90s/it]"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    dia_id = int(row[\"Dialogue_ID\"])\n",
    "    utt_id = int(row[\"Utterance_ID\"])\n",
    "    uid = f\"dia{dia_id}_utt{utt_id}\"\n",
    "\n",
    "    video_path = os.path.join(VIDEO_DIR, f\"{uid}.mp4\")\n",
    "    audio_path = os.path.join(AUDIO_DIR, f\"{uid}.wav\")\n",
    "    if not (os.path.exists(video_path) and os.path.exists(audio_path)):\n",
    "        continue\n",
    "\n",
    "    # 已存在则跳过（断点续跑）\n",
    "    out_file = os.path.join(SAVE_PATH , f\"{uid}.pt\")\n",
    "    if os.path.exists(out_file):\n",
    "        continue\n",
    "\n",
    "    # ========== 预处理 ==========\n",
    "    try:\n",
    "        inputs = {\n",
    "            ModalityType.TEXT:   data.load_and_transform_text([str(row[\"Utterance\"])], device),         # [1, L]\n",
    "            ModalityType.VISION: data.load_and_transform_video_data([video_path], device),              # [1, 15, 3, T, 224, 224]\n",
    "            ModalityType.AUDIO:  data.load_and_transform_audio_data([audio_path], device),              # [1, 3, 1, 128, 204]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] preprocess failed on {uid}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # 可选：打印一次形状核对\n",
    "    # print(\"TEXT  :\", inputs[ModalityType.TEXT].shape)\n",
    "    # print(\"AUDIO :\", inputs[ModalityType.AUDIO].shape)\n",
    "    # print(\"VISION:\", inputs[ModalityType.VISION].shape)\n",
    "\n",
    "    # ========== 单次前向（不分 CHUNK）==========\n",
    "    try:\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():  \n",
    "            emb = model(inputs)\n",
    "    except RuntimeError as oom:\n",
    "        print(f\"[OOM] {uid}: {oom}\")\n",
    "        # 如果这里 OOM，可尝试把 UniformTemporalSubsample 的帧数从 2 再降低，或去掉 autocast\n",
    "        continue\n",
    "\n",
    "    text_emb  = emb[ModalityType.TEXT].detach().cpu()          # [1, 1024]\n",
    "    audio_emb = emb[ModalityType.AUDIO].detach().cpu()         # [1, 1024]\n",
    "    video_raw = emb[ModalityType.VISION].detach().cpu()        # [15, 1024] 或 [1,15,1024] 视实现而定\n",
    "    if video_raw.dim() == 3:   # [1, 15, 1024] -> [15, 1024]\n",
    "        video_raw = video_raw.squeeze(0)\n",
    "    video_emb = video_raw.mean(dim=0, keepdim=True)            # [1, 1024]\n",
    "\n",
    "    # ========== 保存 ==========\n",
    "    torch.save({\n",
    "        \"id\": uid,\n",
    "        \"text_emb\":  text_emb,\n",
    "        \"audio_emb\": audio_emb,\n",
    "        \"video_emb\": video_emb,\n",
    "        \"meta\": {\n",
    "            \"Speaker\":   row[\"Speaker\"],\n",
    "            \"Emotion\":   row[\"Emotion\"],\n",
    "            \"Sentiment\": row[\"Sentiment\"],\n",
    "            \"Season\":    row[\"Season\"],\n",
    "            \"Episode\":   row[\"Episode\"],\n",
    "            \"StartTime\": row[\"StartTime\"],\n",
    "            \"EndTime\":   row[\"EndTime\"],\n",
    "        }\n",
    "    }, out_file)\n",
    "\n",
    "    del inputs, emb, text_emb, audio_emb, video_emb, video_raw\n",
    "    torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "print(\" All embeddings saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a99d03-6f36-4383-a9d5-ca3e642d62f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f7d11-7df9-4304-b29a-2cd6736231cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
